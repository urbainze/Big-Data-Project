Instructios pour lancer l'application:
1- tu te place dans le dossier big_data : cd big_data
2- tu lance les conteneurs : docker-compose up
3- tu crée un topic :docker exec -it kafka kafka-topics --create --topic purchasedata --partitions 1 --replication-factor 1 --bootstrap-s
4- dans ton terminal tu install python-kafka : pip install kafka-python
5- etant dans le dossier big_data tu lance le producer : python(ou python3) purchase_data.py
6- tu entre dans le conteneur spark : docker exec -it spark bash 
7- une fois dans spark tu lance : spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.apache.spark:spark-streaming-kafka-0-10_2.12:3.5.0 processing_data.py
8- ensuite tu va dans ton navigateur tu lance localhost:3000 il te conduira à l'interface de grafana . username : admin , password : admin
9- tu te connecte à ta base de donné : url host : postgres:5432 , user: postgresuser , password : postgrespass , databasename : postgresdb, ssl_mode tu mets :disable 
10- tu peux commencer à faire des queries 

