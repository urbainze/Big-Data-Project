# Real Time data Analysis using kafka,pyspark, postresQl and Grafana

## overview
Nowadays, companies are dealing with an increasing amount of data. Therefore, it is important to build efficient data pipelines to handle these large volumes of data. Sometimes, companies may need to have a real-time overview of their data for possible decision-making. The aim of this project is to demonstrate how you can handle streaming data to build insightful dashboards using Apache Spark for generating streaming data, Apache Kafka for processing them in real-time, PostgreSQL for saving this data, and Grafana for building insightful visualizations

## Data Architecture
![Github Logo](https://github.com/urbainze/Big-Data-Project/blob/main/i9.PNG)

## setting up the environement 
we'll be using a set of docker containers . more details are given below to help you setting up the conatainers .

## prerequisities
Eusre you have Docker installed . whether you are using Linux , mac or windows it's quite easy to get Docker installed on you machine .
if you don't know how to install Docker you can follow the steps in these links to do it . for [mac](https://docs.docker.com/desktop/install/mac-install/) , for [Linux](https://docs.docker.com/desktop/install/linux-install/) and this one for [Windows](https://docs.docker.com/desktop/install/windows-install/) 
